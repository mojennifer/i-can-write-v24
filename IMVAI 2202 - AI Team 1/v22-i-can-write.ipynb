{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","print(\"tensorflow: \", tf.__version__)\n","\n","from tensorflow import keras\n","print(\"keras:\", keras.__version__)"],"metadata":{"trusted":true,"id":"IhDPL8Opo2g8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- NumPy is a Python library used for working with arrays.\n","import numpy as np \n","#-- Pandas is a Python library used for working with data sets.\n","import pandas as pd \n","#-- Pyplot contains various functions that help matplotlib behave like MATLAB.\n","import matplotlib\n","#-- Agg, is a non-interactive backend that can only write to files. \n","#-- It is used on Linux, if Matplotlib cannot connect to either an X display.\n","matplotlib.use('agg')\n","import matplotlib.pyplot as plt \n","\n","#-- OpenCV-Python is a library of Python bindings designed to solve computer vision problems\n","import cv2\n","#-- Performs interpolation to up-size or down-size images.\n","from skimage.transform import resize \n","\n","#-- The OS module in python provides functions for interacting with the operating system.\n","import os\n","#-- pseudo-random generator\n","import random \n","#-- regular expression\n","import re\n","\n","#-- Switching from one backend to another.\n","from tensorflow.keras import backend as K \n","#-- A collection of examples for learning mathematical modelling\n","from tensorflow.keras import optimizers \n","#-- Keras ImageDataGenerator is used for getting the input of the original data and further, \n","#--  it makes the transformation of this data on a random basis and gives the output\n","# from tensorflow.keras.preprocessing.image import ImageDataGenerator \n","#-- collection of utilities for array and list manipulation\n","from tensorflow.keras.utils import to_categorical\n","#-- Sequential groups a linear stack of layers into a tf.keras.Model.  \n","#-- Sequential provides training and inference features on this model.\n","from tensorflow.keras.models import Sequential, load_model \n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.utils import plot_model"],"metadata":{"trusted":true,"id":"iNVsdV3Ao2g_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dir = \"../input/i-can-write/handwritten-numeric-v3/train/\"\n","train_data = []\n","\n","for i in os.listdir(train_dir):\n","    sub_directory = os.path.join(train_dir,i)\n","    count = 0\n","    for j in os.listdir(sub_directory):\n","        count+=1\n","        if count > 3000:\n","            break\n","        #-- Load the image, force it to be in grayscale format, and force the size to be 32×32 pixels\n","        filename = os.path.join(sub_directory,j)\n","        #read image as grayscale\n","        img_gray = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n","        # define a threshold, 128 is the middle of black and white in grayscale\n","        thresh = 128\n","        # threshold the image\n","        img_binary = cv2.threshold(img_gray, thresh, 255, cv2.THRESH_BINARY)[1]\n","        img = np.array(img_binary)\n","        img = img.reshape(32,32,1)\n","        train_data.append([img,i])\n","len(train_data)"],"metadata":{"trusted":true,"id":"1LjV-Ldvo2hB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_dir = \"../input/i-can-write/handwritten-numeric-v3/validation/\"\n","val_data = []\n","\n","for i in os.listdir(val_dir):\n","    sub_directory = os.path.join(val_dir,i)\n","    count = 0\n","    for j in os.listdir(sub_directory):\n","        count+=1\n","        if count > 750:\n","            break\n","        #-- Load the image, force it to be in grayscale format, and force the size to be 32×32 pixels\n","        filename = os.path.join(sub_directory,j)\n","        #read image as gray scale\n","        img_gray = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n","        # define a threshold, 128 is the middle of black and white in grayscale\n","        thresh = 128\n","        # threshold the image\n","        img_binary = cv2.threshold(img_gray, thresh, 255, cv2.THRESH_BINARY)[1]\n","        img = np.array(img_binary)\n","        img = img.reshape(32,32,1)\n","        val_data.append([img,i])\n","len(val_data)"],"metadata":{"trusted":true,"id":"Y2ebhyHpo2hB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["random.shuffle(train_data)\n","random.shuffle(val_data)\n","\n","train_X = []\n","_train_Y = []\n","for features,label in train_data:\n","    train_X.append(features)\n","    _train_Y.append(label)\n","    \n","val_X = []\n","_val_Y = []\n","for features,label in val_data:\n","    val_X.append(features)\n","    _val_Y.append(label)"],"metadata":{"trusted":true,"id":"1_BCnyhto2hC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Inspect a few examples in the dataset\n","fig = plt.figure()\n","for i in range(9):\n","  plt.subplot(3,3,i+1)\n","  plt.tight_layout()\n","  plt.imshow(train_X[i], cmap='gray', interpolation='none')\n","  plt.title(\"Digit: {}\".format(_train_Y[i]))\n","  plt.xticks([])\n","  plt.yticks([])\n","fig"],"metadata":{"trusted":true,"id":"kRdwxp29o2hD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- This is an example of the distribution graph of the pixel values.\n","fig = plt.figure()\n","j = 0\n","plt.subplot(2,1,1)\n","plt.imshow(train_X[j], cmap='gray', interpolation='none')\n","plt.title(\"Digit: {}\".format(_train_Y[j]))\n","plt.xticks([])\n","plt.yticks([])\n","plt.subplot(2,1,2)\n","plt.hist(train_X[j].reshape(1024))\n","plt.title(\"Pixel Value Distribution\")\n","fig"],"metadata":{"trusted":true,"id":"UN_scZABo2hD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Pixel values range from 0 to 255: the background majority close to 0 (black), \n","#--   and those close to 255 (white) representing the digit.\n","\n","train_X = np.array(train_X)\n","val_X = np.array(val_X)\n","\n","train_X = train_X.astype('float32')\n","val_X = val_X.astype('float32')\n","\n","train_X = train_X.reshape(train_X.shape[0],32,32,1)\n","val_X = val_X.reshape(val_X.shape[0],32,32,1)\n","\n","#-- zero-centered data\n","#train_X -= np.mean(train_X, axis=0)\n","#val_X -= np.mean(val_X, axis=0)\n","\n","#-- Normalize the pixel values to lie between 0 and 1\n","#train_X /= 255\n","#val_X /= 255\n","\n","_train_Y = np.array(_train_Y, dtype='uint8')\n","_val_Y = np.array(_val_Y, dtype='uint8')\n","\n","#-- Print the final shape ready for training\n","print(\"matrix shape (train_X|_train_Y) :\", train_X.shape,_train_Y.shape)\n","print(\"matrix shape (  val_X|  _val_Y) :\", val_X.shape,_val_Y.shape)"],"metadata":{"trusted":true,"id":"MkNUiu_to2hE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- the truth (Y in machine learning lingo) used for training still holds integer values from 0 to 9.\n","#-- uint8 is an unsigned 8-bit integer that can represent values 0..255\n","print(np.unique(_val_Y, return_counts=True))"],"metadata":{"trusted":true,"id":"v21tbn_Ko2hF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- one-hot encoding using keras' numpy-related utilities\n","#-- The vector is all zeroes except in the position for the respective category.\n","#-- For example, a '5' will be represented by [0,0,0,0,0,1,0,0,0,0].\n","n_classes = 10\n","print(\"Shape (_train_Y) before one-hot encoding:\", _train_Y.shape)\n","print(\"Shape (  _val_Y) before one-hot encoding:\", _val_Y.shape)\n","train_Y = keras.utils.to_categorical(_train_Y, n_classes)\n","val_Y = keras.utils.to_categorical(_val_Y, n_classes)\n","print(\"Shape (train_Y) after  one-hot encoding:\", train_Y.shape)\n","print(\"Shape (  val_Y) after  one-hot encoding: \", val_Y.shape)"],"metadata":{"trusted":true,"id":"0-kXeD81o2hF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Building a linear stack of layers with the sequential model\n","model = Sequential()\n","\n","model.add(Conv2D(32,(5,5), kernel_initializer='he_uniform', input_shape=(32,32,1)))\n","model.add(tf.keras.layers.PReLU())\n","model.add(MaxPooling2D((2, 2)))\n","model.add(BatchNormalization())\n","\n","model.add(Conv2D(32,(3,3), kernel_initializer='he_uniform'))\n","model.add(tf.keras.layers.PReLU())\n","model.add(Conv2D(64,(3,3), kernel_initializer='he_uniform'))\n","model.add(tf.keras.layers.PReLU())\n","model.add(Conv2D(64,(3,3), kernel_initializer='he_uniform'))\n","model.add(tf.keras.layers.PReLU())\n","model.add(MaxPooling2D((2, 2)))\n","model.add(Dropout(0.2))\n","\n","model.add(Flatten())\n","\n","model.add(Dense(128, kernel_initializer='he_uniform'))\n","model.add(tf.keras.layers.PReLU())\n","\n","model.add(Dense(10, activation='softmax'))\n","\n","model.summary()\n","\n","# plot model architecture\n","plot_model(model, show_shapes='true', to_file='cnn.png')"],"metadata":{"trusted":true,"id":"8woPe9hIo2hG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Compiling the sequential model\n","model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n","#opt = SGD(learning_rate=0.01, momentum=0.9)\n","#model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=opt)"],"metadata":{"trusted":true,"id":"dYw4tq_2o2hG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Training the model and saving metrics in history\n","history = model.fit(train_X, train_Y,\n","          batch_size=128, epochs=10,\n","          verbose=2,\n","          validation_data=(val_X, val_Y))"],"metadata":{"trusted":true,"id":"W9ma-Oofo2hH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save('handwriting.h5')"],"metadata":{"trusted":true,"id":"z5vCY91Ko2hH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Plotting the metrics\n","fig = plt.figure()\n","\n","plt.subplot(2,1,1)\n","x = np.arange(1., 11., 1.0)\n","plt.plot(x, history.history['accuracy'])\n","plt.plot(x, history.history['val_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.xticks(np.arange(0, 11, 1))\n","plt.xlim(right=11)\n","plt.legend(['train', 'validation'], loc='lower right')\n","\n","plt.subplot(2,1,2)\n","x = np.arange(1., 11., 1.0)\n","plt.plot(x, history.history['loss'])\n","plt.plot(x, history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.xticks(np.arange(0, 11, 1))\n","plt.xlim(right=11)\n","plt.legend(['train', 'validation'], loc='upper right')\n","\n","#plt.tight_layout()\n","fig.subplots_adjust(hspace=0.8, wspace=0.8)\n","fig"],"metadata":{"trusted":true,"id":"jgFAjWfWo2hH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = load_model('handwriting.h5')\n","loss_and_metrics = model.evaluate(val_X, val_Y, verbose=2)\n","\n","print(\"Validation Loss\", loss_and_metrics[0])\n","print(\"Validation Accuracy\", loss_and_metrics[1])"],"metadata":{"trusted":true,"id":"RjiK3Vg9o2hI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Load the model and create predictions on the validation set\n","model = load_model('handwriting.h5')\n","predicted_classes = np.argmax(model.predict(val_X), axis=1)\n","\n","#-- See which we predicted correctly and which not\n","correct_indices = np.nonzero(predicted_classes == _val_Y)[0]\n","incorrect_indices = np.nonzero(predicted_classes != _val_Y)[0]\n","print()\n","print(len(correct_indices),\" classified correctly\")\n","print(len(incorrect_indices),\" classified incorrectly\")"],"metadata":{"trusted":true,"id":"ItVyxYJyo2hI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-- Adapt figure size to accomodate 18 subplots\n","plt.rcParams['figure.figsize'] = (7,14)\n","\n","figure_evaluation = plt.figure()\n","\n","#-- Plot 9 correct predictions\n","#for i, correct in enumerate(correct_indices[:9]):\n","#    plt.subplot(6,3,i+1)\n","#    plt.imshow(val_X[correct].reshape(32,32), cmap='gray', interpolation='none')\n","#    plt.title(\n","#      \"Predicted: {}, Truth: {}\".format(predicted_classes[correct],\n","#                                        _val_Y[correct]))\n","#    plt.xticks([])\n","#    plt.yticks([])\n","\n","#-- Plot 9 incorrect predictions\n","for i, incorrect in enumerate(incorrect_indices[:9]):\n","    plt.subplot(6,3,i+10)\n","    plt.imshow(val_X[incorrect].reshape(32,32), cmap='gray', interpolation='none')\n","    plt.title(\n","      \"Predicted: {}, Truth: {}\".format(predicted_classes[incorrect],\n","                                        _val_Y[incorrect]))\n","    plt.xticks([])\n","    plt.yticks([])\n","\n","figure_evaluation"],"metadata":{"trusted":true,"id":"Ep7Epq8Co2hI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prediction_static(filename):\n","    number = re.search(r\"\\d\",filename)\n","    actual = number.group()\n","    mypath = os.path.join(\"../input/i-can-write/handwritten-numeric-v3/holdout_static/\",filename)\n","    #read image as grayscale\n","    img_gray = cv2.imread(mypath, cv2.IMREAD_GRAYSCALE)\n","    # define a threshold, 128 is the middle of black and white in grayscale\n","    thresh = 128\n","    # threshold the image\n","    img_binary = cv2.threshold(img_gray, thresh, 255, cv2.THRESH_BINARY)[1]\n","    img = np.invert(img_binary)\n","    img = img.astype('float32')\n","    img_re = resize(img,(32,32,1))\n","    img_re = img_re.reshape(32,32,1)\n","    #img_re -= np.mean(img_re, axis=0)\n","    #img_re /= 255\n","    probabilities = model.predict(np.array([img_re],))[0,:]\n","    number_to_class = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n","    index = np.argsort(probabilities)\n","    if number_to_class[index[9]] == actual:\n","     grade = \"Good Job!\"\n","    else:\n","     grade = \"Hmmm ... Did I make a wrong guess?\"\n","    predictions = {\n","      \"actual\":actual,\n","      \"digit\":number_to_class[index[9]],\n","      \"prob\" :probabilities[index[9]],\n","      \"comment\":grade\n","    }\n","    return predictions, img_re"],"metadata":{"trusted":true,"id":"PAdYJx5Xo2hI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions_static = ()\n","number = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n","for i in number:\n","    myfile = i + \".jpg\"\n","    predictions, img_re = prediction_static(myfile)\n","    print(predictions)"],"metadata":{"trusted":true,"id":"DOsgy6tco2hJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def crop_square(img, size, interpolation=cv2.INTER_AREA):\n","    h, w = img.shape[:2]\n","    min_size = np.amin([h,w])\n","    # Centralize and crop\n","    crop_img = img[int(h/2-(min_size/2)):int(h/2+(min_size/2)), int(w/2-(min_size/2)):int(w/2+(min_size/2))]\n","    resized = cv2.resize(crop_img, (size, size), interpolation=interpolation)\n","\n","    return resized"],"metadata":{"trusted":true,"id":"YDg4gmgyo2hJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prediction(filename):\n","    number = re.search(r\"\\d\",filename)\n","    actual = number.group()\n","    mypath = os.path.join(\"../input/i-can-write/handwritten-numeric-v3/holdout/\",filename)\n","    #read image as grayscale\n","    img_gray = cv2.imread(mypath, cv2.IMREAD_GRAYSCALE)\n","    # define a threshold, 128 is the middle of black and white in grayscale\n","    thresh = 128\n","    # threshold the image\n","    img_bin = cv2.threshold(img_gray, thresh, 255, cv2.THRESH_BINARY)[1]\n","    img_bin = np.invert(img_bin)\n","    img_bin = img_bin.astype('float32')\n","    crop_rows = img_bin[~np.all(img_bin==0, axis=1), :]\n","    cropped_image = crop_rows[:, ~np.all(crop_rows==0, axis=0)]\n","    top, bottom, left, right = [10]*4\n","    img = cv2.copyMakeBorder(cropped_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0,0,0])\n","    img = crop_square(img, 32, cv2.INTER_AREA)\n","    img = cv2.threshold(img, thresh, 255, cv2.THRESH_BINARY)[1]\n","    img_re = img.reshape(32,32,1)\n","    #img_re -= np.mean(img_re, axis=0)\n","    #img_re /= 255\n","    probabilities = model.predict(np.array([img_re],))[0,:]\n","    number_to_class = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n","    index = np.argsort(probabilities)\n","    if number_to_class[index[9]] == actual:\n","     grade = \"Good Job!\"\n","    else:\n","     grade = \"Hmmm ... Did I make a wrong guess?\"\n","    predictions = {\n","      \"actual\":actual,\n","      \"digit\":number_to_class[index[9]],\n","      \"prob\" :probabilities[index[9]],\n","      \"comment\":grade\n","    }\n","    return predictions, img_gray, img_bin, cropped_image, img, img_re"],"metadata":{"trusted":true,"id":"ClcbEHKco2hJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = ()\n","number = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n","#number = [\"6\"]\n","for i in number:\n","    myfile = i + \".jpg\"\n","    predictions, img_gray, img_bin, cropped_image, img, img_re = prediction(myfile)\n","    print(predictions)"],"metadata":{"trusted":true,"id":"0lAGYbljo2hJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#fig = plt.figure()\n","#plt.imshow(img, cmap='gray', interpolation='none')\n","#fig"],"metadata":{"trusted":true,"id":"8M7LXmJdo2hK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#%matplotlib inline\n","#import seaborn as sns\n","\n","#img = cv2.imread(\"../input/i-can-write/handwritten-numeric-v3/validation/4/30000.jpg\", cv2.IMREAD_GRAYSCALE)\n","#thresh = 128\n","#img = cv2.threshold(img, thresh, 255, cv2.THRESH_BINARY)[1]\n","#img = np.array(img)\n","# with np.printoptions(threshold=np.inf):\n","#    print(img)\n","\n","#f, ax = plt.subplots(figsize=(32,32))\n","#sns.heatmap(img, annot=True, fmt='.1f', square=True, cmap=\"gray\")\n","#plt.show()"],"metadata":{"trusted":true,"id":"rOCioeKwo2hK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot feature map of first conv layer for given image\n","#from tensorflow.keras.applications.vgg16 import VGG16\n","#from tensorflow.keras.applications.vgg16 import preprocess_input\n","#from tensorflow.keras.preprocessing.image import load_img\n","#from tensorflow.keras.preprocessing.image import img_to_array\n","#from tensorflow.keras.models import Model\n","#from matplotlib import pyplot\n","#from numpy import expand_dims\n","\n","# load the model\n","#model = VGG16()\n","# redefine model to output right after the first hidden layer\n","#model = Model(inputs=model.inputs, outputs=model.layers[1].output)\n","#model.summary()\n","# load the image with the required shape\n","#img = load_img('../input/i-can-write/handwritten-numeric-v3/validation/3/30004.jpg', target_size=(224, 224))\n","# convert the image to an array\n","#img = img_to_array(img)\n","# expand dimensions so that it represents a single 'sample'\n","#img = expand_dims(img, axis=0)\n","# prepare the image (e.g. scale pixel values for the vgg)\n","#img = preprocess_input(img)\n","# get feature map for first hidden layer\n","#feature_maps = model.predict(img)\n","# plot all 64 maps in an 8x8 squares\n","#square = 8\n","#ix = 1\n","#for _ in range(square):\n","#    for _ in range(square):\n","#        # specify subplot and turn of axis\n","#        ax = pyplot.subplot(square, square, ix)\n","#        ax.set_xticks([])\n","#        ax.set_yticks([])\n","#        # plot filter channel in grayscale\n","#        pyplot.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\n","#        ix += 1\n","# show the figure\n","#plt.show()"],"metadata":{"trusted":true,"id":"uxaV1qSQo2hK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#import shutil\n","#shutil.rmtree(\"/kaggle/working/\")"],"metadata":{"trusted":true,"id":"gtXQRnh9o2hK"},"execution_count":null,"outputs":[]}]}